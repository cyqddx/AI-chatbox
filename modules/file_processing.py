import os
import datetime
import uuid
import shutil
import re
from pathlib import Path
from typing import Any
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import docx2txt
import gradio as gr

# ğŸ“„ æ–‡æ¡£åŠ è½½å™¨
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredPowerPointLoader,
    UnstructuredHTMLLoader,
    NotebookLoader,
    UnstructuredWordDocumentLoader,
)

# ğŸ§© æ–‡æœ¬åˆ†å—
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ğŸ—„ï¸ å‘é‡æ•°æ®åº“
import chromadb
from chromadb.config import Settings

# âš™ï¸ é¡¹ç›®é…ç½®
from config import config
from utils.logger import logger
from utils.database import db_manager

# ğŸ’¬ èŠå¤©ç®¡ç†ï¼ˆç”¨äºè¿›åº¦æç¤ºï¼‰
from modules.chat_management import chat_manager

class FileProcessor:
    """
    ğŸ“ æ–‡ä»¶å¤„ç†æ¨¡å— - å¢å¼ºç‰ˆ
    åŠŸèƒ½ï¼š
        1. ğŸ“„ æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼ˆPDFã€DOCXã€TXTã€PPTXã€HTMLã€IPYNBï¼‰
        2. ğŸ’¾ è‡ªåŠ¨ä¿å­˜ä¸Šä¼ æ–‡ä»¶åˆ°æœ¬åœ°
        3. âœ‚ï¸ æ–‡æœ¬æ™ºèƒ½åˆ†å—å¤„ç†
        4. ğŸ—„ï¸ å‘é‡åŒ–å­˜å‚¨åˆ° ChromaDBï¼ˆä¼šè¯éš”ç¦»ï¼‰
        5. ğŸ“Š å®æ—¶è¿›åº¦åé¦ˆ
        6. â±ï¸ è¶…æ—¶ä¿æŠ¤æœºåˆ¶
    
    è®¾è®¡åŸåˆ™ï¼š
        - ğŸ”„ å…¼å®¹æ€§ï¼šå®Œå…¨é€‚é… Gradio 5.42.0 çš„ FileData å¯¹è±¡
        - ğŸ›¡ï¸ å¥å£®æ€§ï¼šå¤šé‡é”™è¯¯å¤„ç†å’Œè¶…æ—¶ä¿æŠ¤
        - ğŸ“ˆ å¯æ‰©å±•æ€§ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ·»åŠ æ–°æ ¼å¼æ”¯æŒ
        - ğŸ”— ä¼šè¯éš”ç¦»ï¼šæ–‡æ¡£åªåœ¨æŒ‡å®šä¼šè¯ä¸­ç”Ÿæ•ˆ
    """

    def __init__(self) -> None:
        """åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨"""
        logger.info("ğŸ“ åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨")
        
        # ğŸ§© æ–‡æœ¬åˆ†å—å™¨é…ç½®
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.CHUNK_SIZE,          # âœ‚ï¸ æ¯ä¸ªå—çš„æœ€å¤§å­—ç¬¦æ•°
            chunk_overlap=config.CHUNK_OVERLAP,    # ğŸ”„ å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
            length_function=len,                   # ğŸ“ é•¿åº¦è®¡ç®—å‡½æ•°
            is_separator_regex=False,             # âŒ ä¸ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†éš”ç¬¦
        )

        # ğŸ—„ï¸ ChromaDB å®¢æˆ·ç«¯é…ç½®
        self.chroma_client = chromadb.PersistentClient(
            path=str(config.VECTOR_STORE_DIR),     # ğŸ—„ï¸ å‘é‡æ•°æ®åº“ä¿å­˜è·¯å¾„
            settings=Settings(allow_reset=True),  # ğŸ”„ å…è®¸é‡ç½®æ•°æ®åº“
        )
        
        # â±ï¸ å¤„ç†è¶…æ—¶è®¾ç½®ï¼ˆç§’ï¼‰
        self.processing_timeout = 60
        
        # ğŸ§µ çº¿ç¨‹æ± ç”¨äºå¼‚æ­¥å¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        # ğŸ“‹ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼æ˜ å°„
        self.supported_formats = {
            "pdf": PyPDFLoader,
            "docx": UnstructuredWordDocumentLoader,
            "txt": lambda p: TextLoader(p, encoding="utf-8"),
            "pptx": UnstructuredPowerPointLoader,
            "html": UnstructuredHTMLLoader,
            "ipynb": NotebookLoader,
        }
        
        logger.info("âœ… æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _get_loader(self, file_type: str) -> Any | None:
        """æ ¹æ®æ–‡ä»¶ç±»å‹è¿”å›å¯¹åº”çš„æ–‡æ¡£åŠ è½½å™¨"""
        loader = self.supported_formats.get(file_type.lower())
        logger.debug(f"ğŸ“‹ è·å–åŠ è½½å™¨: {file_type} -> {loader}")
        return loader

    def save_file(self, file_data: Any, phone: str, sid: str) -> str:
        """
        ğŸ’¾ ä¿å­˜ä¸Šä¼ æ–‡ä»¶ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        å‚æ•°:
            file_data: Gradio 5.42.0 çš„ FileData å¯¹è±¡
            phone: ç”¨æˆ·æ‰‹æœºå·ï¼ˆç”¨äºç”¨æˆ·ç›®å½•éš”ç¦»ï¼‰
            sid: ä¼šè¯ID (UUIDæ ¼å¼ï¼Œç”¨äºä¼šè¯éš”ç¦»)
            
        è¿”å›:
            ä¿å­˜åçš„å®Œæ•´æ–‡ä»¶è·¯å¾„
        """
        try:
            logger.info(f"ğŸ’¾ å¼€å§‹ä¿å­˜æ–‡ä»¶: ç”¨æˆ·={phone}, ä¼šè¯={sid}")
            
            # ğŸ“ ä¸¥æ ¼éªŒè¯UUIDæ ¼å¼
            try:
                uuid.UUID(str(sid))
                sid_str = str(sid)
            except (ValueError, TypeError):
                logger.error(f"âŒ æ— æ•ˆçš„ä¼šè¯IDæ ¼å¼: {sid}")
                raise ValueError(f"æ— æ•ˆçš„ä¼šè¯ID: {sid}")

            # ğŸ“‹ è·å–æ–‡ä»¶ä¿¡æ¯ - ä¿®å¤æ–‡ä»¶åæå–
            if hasattr(file_data, 'name'):
                # ğŸ¯ Gradio FileData å¯¹è±¡
                original_filename = str(file_data.name)
                source_path = Path(file_data.name) if hasattr(file_data, 'path') else None
            elif hasattr(file_data, 'orig_name'):
                # ğŸ“ å¤‡ç”¨æ–¹æ¡ˆ
                original_filename = str(file_data.orig_name)
                source_path = None
            else:
                # ğŸš¨ å…œåº•æ–¹æ¡ˆ
                original_filename = str(file_data).split('/')[-1]  # æå–æ–‡ä»¶å
                source_path = None
            
            # ğŸ§¹ æ¸…ç†æ–‡ä»¶å
            original_filename = self.sanitize_filename(original_filename)
            file_type = Path(original_filename).suffix.lower().lstrip(".")

            logger.info(f"ğŸ“‹ æ–‡ä»¶ä¿¡æ¯: åç§°={original_filename}, ç±»å‹={file_type}")

            # âœ… éªŒè¯æ–‡ä»¶æ ¼å¼
            if file_type not in config.SUPPORTED_FILE_FORMATS:
                error_msg = (
                    f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_type}\n"
                    f"âœ… æ”¯æŒçš„æ ¼å¼: {', '.join(config.SUPPORTED_FILE_FORMATS)}"
                )
                logger.error(error_msg)
                raise ValueError(error_msg)

            # ğŸ“ åˆ›å»ºç”¨æˆ·ä¸“å±ç›®å½•ï¼ˆç”¨æˆ·çº§éš”ç¦»ï¼‰
            user_dir = config.UPLOADS_DIR / phone
            user_dir.mkdir(parents=True, exist_ok=True)

            # ğŸ“ åˆ›å»ºä¼šè¯ä¸“å±ç›®å½•ï¼ˆä¼šè¯çº§éš”ç¦»ï¼‰
            session_dir = user_dir / sid_str
            session_dir.mkdir(parents=True, exist_ok=True)

            # ğŸ†” ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            unique_filename = f"{uuid.uuid4().hex}_{original_filename}"
            save_path = session_dir / unique_filename
            save_path = save_path.resolve()

            # ğŸ“‹ éªŒè¯ç›®å½•å­˜åœ¨
            if not save_path.parent.exists():
                logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {save_path.parent}")
                raise ValueError(f"æ— æ³•åˆ›å»ºä¿å­˜ç›®å½•: {save_path.parent}")

            # ğŸ’¾ å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
            if hasattr(file_data, 'path') and file_data.path and Path(file_data.path).exists():
                # ğŸ“ ç›´æ¥å¤åˆ¶ - ä½¿ç”¨ç»å¯¹è·¯å¾„
                source_path = Path(file_data.path)
                shutil.copy2(str(source_path), str(save_path))
                logger.info(f"âœ… æ–‡ä»¶å¤åˆ¶æˆåŠŸ: {source_path} -> {save_path}")
            elif hasattr(file_data, 'read'):
                # ğŸ“„ ä»æ–‡ä»¶å¯¹è±¡è¯»å–
                file_bytes = file_data.read()
                with open(save_path, "wb") as f:
                    f.write(file_bytes)
                logger.info(f"âœ… æ–‡ä»¶å­—èŠ‚å†™å…¥æˆåŠŸ: {save_path}")
            else:
                # ğŸ“„ ä»å­—ç¬¦ä¸²è·¯å¾„è¯»å–
                try:
                    source_path = Path(str(file_data))
                    if source_path.exists():
                        shutil.copy2(str(source_path), str(save_path))
                        logger.info(f"âœ… æ–‡ä»¶å¤åˆ¶æˆåŠŸ: {source_path} -> {save_path}")
                    else:
                        # ğŸ“ å­—ç¬¦ä¸²è½¬å­—èŠ‚
                        file_bytes = bytes(str(file_data), "utf-8")
                        with open(save_path, "wb") as f:
                            f.write(file_bytes)
                        logger.info(f"âœ… æ–‡ä»¶å­—èŠ‚å†™å…¥æˆåŠŸ: {save_path}")
                except Exception:
                    # ğŸš¨ æœ€åå°è¯•
                    with open(save_path, "wb") as f:
                        f.write(str(file_data).encode('utf-8'))
                    logger.info(f"âœ… æ–‡ä»¶å­—ç¬¦ä¸²å†™å…¥æˆåŠŸ: {save_path}")

            # ğŸ—„ï¸ è®°å½•åˆ°æ•°æ®åº“
            file_id = db_manager.add_file(
                sid=sid_str,
                file_path=str(save_path),
                file_name=original_filename,  # ğŸ“‹ ä½¿ç”¨æ¸…ç†åçš„æ–‡ä»¶å
                file_type=file_type,
                uploaded_at=datetime.datetime.now().isoformat(),
            )

            logger.info(f"ğŸ‰ æ–‡ä»¶ä¿å­˜å®Œæˆ: {original_filename} -> {save_path} (ID: {file_id})")
            return str(save_path)

        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
            raise ValueError(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")

    def load_document(self, file_path: Path, file_type: str) -> list[Any] | None:
        """
        ğŸ“– åŠ è½½å¹¶è§£ææ–‡æ¡£ - å¸¦è¶…æ—¶ä¿æŠ¤
        
        å‚æ•°:
            file_path: æ–‡ä»¶å®Œæ•´è·¯å¾„
            file_type: æ–‡ä»¶æ‰©å±•å
            
        è¿”å›:
            æ–‡æ¡£å†…å®¹åˆ—è¡¨æˆ–None
        """
        try:
            loader_class = self._get_loader(file_type)
            if loader_class is None:
                logger.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
                return None

            abs_path = file_path.resolve()
            if not abs_path.exists():
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}")
                return None

            logger.info(f"ğŸ“– å¼€å§‹åŠ è½½æ–‡æ¡£: {abs_path}")

            def _load_document():
                """å†…éƒ¨æ–‡æ¡£åŠ è½½å‡½æ•°"""
                try:
                    # ğŸ“ ç‰¹æ®Šå¤„ç† Word æ–‡æ¡£
                    if file_type == "docx":
                        try:
                            text = docx2txt.process(str(abs_path))
                            from langchain_core.documents import Document
                            return [Document(page_content=text, metadata={"source": str(abs_path)})]
                        except ImportError:
                            logger.error("âŒ è¯·å®‰è£…docx2txt: pip install docx2txt")
                            return None
                        except Exception as e:
                            logger.error(f"âŒ docx2txtå¤„ç†å¤±è´¥: {e}")
                            return None
                    else:
                        # ğŸ“„ å…¶ä»–æ ¼å¼ç›´æ¥åŠ è½½
                        loader = loader_class(str(abs_path))
                        documents = loader.load()

                    if not documents:
                        logger.warning(f"âš ï¸ æ–‡æ¡£å†…å®¹ä¸ºç©º: {abs_path}")
                        return None

                    logger.info(f"âœ… æ–‡æ¡£åŠ è½½æˆåŠŸ: {abs_path} - {len(documents)} ä¸ªæ–‡æ¡£")
                    return documents
                except Exception as e:
                    logger.error(f"âŒ æ–‡æ¡£åŠ è½½å¼‚å¸¸: {str(e)}")
                    return None

            # ğŸ§µ ä½¿ç”¨çº¿ç¨‹æ± å’Œè¶…æ—¶ä¿æŠ¤
            future = self.executor.submit(_load_document)
            documents = future.result(timeout=self.processing_timeout)

            return documents

        except TimeoutError:
            logger.error(f"â±ï¸ æ–‡æ¡£åŠ è½½è¶…æ—¶: {file_path} ({self.processing_timeout}ç§’)")
            return None
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {file_path} - {str(e)}")
            return None

    def process_file(self, sid: str, file_path: Path, file_name: str, file_type: str) -> bool:
        """
        ğŸ”„ å¤„ç†å•ä¸ªæ–‡ä»¶ - ä¼šè¯éš”ç¦»ç‰ˆ
        é‡è¦ï¼šç¡®ä¿æ–‡æ¡£åªåœ¨æŒ‡å®šçš„ä¼šè¯ä¸­ç”Ÿæ•ˆ
        
        å‚æ•°:
            sid: ä¼šè¯ID (UUIDæ ¼å¼)
            file_path: æ–‡ä»¶è·¯å¾„
            file_name: åŸå§‹æ–‡ä»¶å
            file_type: æ–‡ä»¶ç±»å‹
            
        è¿”å›:
            å¤„ç†æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™False
        """
        try:
            # ğŸ” ä¸¥æ ¼éªŒè¯UUIDæ ¼å¼
            try:
                session_uuid = uuid.UUID(str(sid))
                sid_str = str(session_uuid)
                logger.info(f"ğŸ”„ [FILE_PROCESS] å¼€å§‹å¤„ç†æ–‡ä»¶: {file_name} (ä¼šè¯UUID: {sid_str})")
            except (ValueError, TypeError):
                logger.error(f"âŒ [FILE_PROCESS] æ— æ•ˆçš„ä¼šè¯UUIDæ ¼å¼: {sid}")
                return False

            logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶: {file_name} (ä¼šè¯: {sid_str})")
            
            # ğŸ’¬ æ·»åŠ ä¸Šä¼ è¿›åº¦æç¤º
            progress_msg = f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡æ¡£: {file_name}..."
            chat_manager.add_message(sid_str, "system", progress_msg)

            # 1. ğŸ“– åŠ è½½æ–‡æ¡£ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
            documents = self.load_document(file_path, file_type)
            if documents is None:
                error_msg = f"âŒ æ— æ³•åŠ è½½æ–‡æ¡£: {file_name}"
                chat_manager.add_message(sid_str, "system", error_msg)
                return False

            # 2. âœ‚ï¸ æ–‡æœ¬åˆ†å—
            try:
                chunks = self.text_splitter.split_documents(documents)
                if not chunks:
                    warning_msg = f"âš ï¸ æ–‡æ¡£åˆ†å—ä¸ºç©º: {file_name}"
                    chat_manager.add_message(sid_str, "system", warning_msg)
                    return False
            except Exception as e:
                error_msg = f"âŒ æ–‡æ¡£åˆ†å—å¤±è´¥: {file_name}"
                chat_manager.add_message(sid_str, "system", error_msg)
                logger.error(f"âŒ æ–‡æ¡£åˆ†å—å¤±è´¥: {file_name} - {str(e)}")
                return False

            logger.info(f"ğŸ“Š åˆ†å—å®Œæˆ: {file_name} - {len(chunks)} ä¸ªå—")

            # 3. ğŸ—„ï¸ è·å–æˆ–åˆ›å»ºä¼šè¯ä¸“å±çš„å‘é‡å­˜å‚¨
            try:
                # ğŸ¯ ä½¿ç”¨ä¼šè¯IDä½œä¸ºé›†åˆåç§°ï¼Œç¡®ä¿ä¼šè¯éš”ç¦»
                collection_name = f"session_{sid_str}"
                collection = self.chroma_client.get_or_create_collection(
                    name=collection_name,
                    metadata={"hnsw:space": "cosine"},
                )
                logger.info(f"âœ… å‘é‡é›†åˆå·²å°±ç»ª: {collection_name}")
            except Exception as e:
                error_msg = f"âŒ å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥"
                chat_manager.add_message(sid_str, "system", error_msg)
                logger.error(f"âŒ å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
                return False

            # 4. ğŸ“ å‡†å¤‡æ•°æ®
            ids = [str(uuid.uuid4()) for _ in chunks]
            texts = [chunk.page_content for chunk in chunks]
            metadatas = [
                {
                    "source": file_name,
                    "chunk_index": i,
                    "file_path": str(file_path.resolve()),
                    "file_type": file_type,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "session_id": sid_str,  # ğŸ¯ æ·»åŠ ä¼šè¯IDæ ‡è®°
                }
                for i in range(len(chunks))
            ]

            # 5. ğŸ“¦ åˆ†æ‰¹å­˜å‚¨åˆ°ä¼šè¯ä¸“å±çš„å‘é‡åº“
            batch_size = 50  # ğŸ¯ æ¯æ‰¹50ä¸ªå—
            total_chunks = len(chunks)
            
            try:
                for i in range(0, total_chunks, batch_size):
                    batch_end = min(i + batch_size, total_chunks)
                    
                    collection.add(
                        ids=ids[i:batch_end],
                        documents=texts[i:batch_end],
                        metadatas=metadatas[i:batch_end],
                    )
                    
                    progress = (batch_end / total_chunks) * 100
                    logger.info(f"ğŸ“¤ ä¸Šä¼ è¿›åº¦: {batch_end}/{total_chunks} ({progress:.1f}%)")
                    
                    # ğŸ“Š æ›´æ–°è¿›åº¦æç¤ºï¼ˆå¤§æ–‡ä»¶ï¼‰
                    if total_chunks > 100:
                        progress_msg = f"ğŸ“Š å¤„ç†ä¸­... {progress:.0f}%"
                        chat_manager.add_message(sid_str, "system", progress_msg)
                
                # âœ… æ·»åŠ æˆåŠŸå¤„ç†æ¶ˆæ¯
                success_msg = f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {file_name} ({len(chunks)} ä¸ªç‰‡æ®µ)"
                chat_manager.add_message(sid_str, "assistant", success_msg)
                
                logger.info(
                    f"ğŸ‰ æ–‡ä»¶å¤„ç†å®Œæˆ: {file_name} -> {len(chunks)} ä¸ªå— "
                    f"(ä¼šè¯: {sid_str})"
                )
                return True
                
            except Exception as e:
                error_msg = f"âŒ å‘é‡å­˜å‚¨å¤±è´¥: {file_name}"
                chat_manager.add_message(sid_str, "system", error_msg)
                logger.error(f"âŒ å‘é‡å­˜å‚¨å¤±è´¥: {file_name} - {str(e)}")
                return False

        except Exception as e:
            error_msg = f"ğŸ’¥ å¤„ç†å‡ºé”™: {file_name}"
            chat_manager.add_message(sid_str, "system", error_msg)
            logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {file_name} - {str(e)}")
            return False

    def process_uploaded_files(self, sid: str) -> int:
        """
        ğŸ“¦ æ‰¹é‡å¤„ç†æœªå¤„ç†æ–‡ä»¶ - ä¼šè¯éš”ç¦»ç‰ˆ
        
        å‚æ•°:
            sid: ä¼šè¯ID (UUIDæ ¼å¼)
        è¿”å›:
            æˆåŠŸå¤„ç†çš„æ–‡ä»¶æ•°é‡
        """
        try:
            # ğŸ” ä¸¥æ ¼éªŒè¯UUIDæ ¼å¼
            try:
                uuid.UUID(str(sid))
                sid_str = str(sid)
            except (ValueError, TypeError):
                logger.error(f"âŒ æ— æ•ˆçš„ä¼šè¯IDæ ¼å¼: {sid}")
                return 0

            logger.info(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å¤„ç†æ–‡ä»¶: ä¼šè¯={sid_str}")
            
            # ğŸ” è·å–è¯¥ä¼šè¯çš„æœªå¤„ç†æ–‡ä»¶
            unprocessed_files = db_manager.get_unprocessed_files(sid_str)
            if not unprocessed_files:
                logger.info(f"â„¹ï¸ ä¼šè¯ {sid_str} æ²¡æœ‰å¾…å¤„ç†æ–‡ä»¶")
                return 0

            processed_count = 0
            file_ids = []

            logger.info(f"ğŸ” å‘ç° {len(unprocessed_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶")

            for file_info in unprocessed_files:
                file_id, file_path, file_name, file_type = file_info

                try:
                    file_path_obj = Path(file_path)
                    if not file_path_obj.exists():
                        logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                        continue

                    success = self.process_file(
                        sid_str, file_path_obj, file_name, file_type
                    )

                    if success:
                        file_ids.append(file_id)
                        processed_count += 1
                        logger.info(f"âœ… å¤„ç†æˆåŠŸ: {file_name}")
                    else:
                        logger.warning(f"âš ï¸ å¤„ç†å¤±è´¥: {file_name}")

                except Exception as e:
                    logger.error(f"ğŸ’¥ å¤„ç†å¼‚å¸¸: {file_name} - {str(e)}")
                    continue

            # ğŸ“ æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†
            if file_ids:
                db_manager.mark_files_processed(file_ids)
                logger.info(f"ğŸ“‹ æ‰¹é‡æ›´æ–°å®Œæˆ: {len(file_ids)} ä¸ªæ–‡ä»¶")

            logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")
            return processed_count

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
            return 0

    def get_file_info(self, file_path: str) -> dict:
        """
        ğŸ“‹ è·å–æ–‡ä»¶ä¿¡æ¯
        
        å‚æ•°:
            file_path: æ–‡ä»¶è·¯å¾„
        è¿”å›:
            æ–‡ä»¶ä¿¡æ¯å­—å…¸
        """
        try:
            path = Path(file_path)
            if not path.exists():
                return {"error": "âŒ æ–‡ä»¶ä¸å­˜åœ¨"}
                
            stat = path.stat()
            info = {
                "name": path.name,
                "size": stat.st_size,
                "type": path.suffix.lower(),
                "modified": datetime.datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "path": str(path)
            }
            logger.info(f"ğŸ“‹ è·å–æ–‡ä»¶ä¿¡æ¯: {info['name']} - {info['size']} bytes")
            return info
        except Exception as e:
            logger.error(f"âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    def get_session_file_status(self, sid: str) -> dict:
        """
        ğŸ“Š è·å–ä¼šè¯çš„æ–‡ä»¶å¤„ç†çŠ¶æ€
        
        å‚æ•°:
            sid: ä¼šè¯ID (UUIDæ ¼å¼å­—ç¬¦ä¸²)
        è¿”å›:
            æ–‡ä»¶çŠ¶æ€å­—å…¸ {
                'total': æ€»æ–‡ä»¶æ•°,
                'processed': å·²å¤„ç†æ–‡ä»¶æ•°,
                'unprocessed': æœªå¤„ç†æ–‡ä»¶æ•°,
                'files': [...]
            }
        """
        try:
            # ğŸ” ä¸¥æ ¼éªŒè¯UUIDæ ¼å¼
            uuid.UUID(str(sid))
            sid_str = str(sid)
            
            # ğŸ“‹ è·å–æ‰€æœ‰æ–‡ä»¶
            all_files = db_manager.get_files_for_session(sid_str)
            
            # ğŸ“Š ç»Ÿè®¡çŠ¶æ€
            processed = [f for f in all_files if f[5] == 1]  # processed=1
            unprocessed = [f for f in all_files if f[5] == 0]  # processed=0
            
            status = {
                'total': len(all_files),
                'processed': len(processed),
                'unprocessed': len(unprocessed),
                'files': all_files
            }
            
            logger.info(
                f"ğŸ“Š ä¼šè¯æ–‡ä»¶çŠ¶æ€: ä¼šè¯={sid_str}, "
                f"æ€»æ•°={len(all_files)}, å·²å¤„ç†={len(processed)}, æœªå¤„ç†={len(unprocessed)}"
            )
            
            return status
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¼šè¯æ–‡ä»¶çŠ¶æ€å¤±è´¥: ä¼šè¯={sid}, é”™è¯¯={str(e)}")
            return {'total': 0, 'processed': 0, 'unprocessed': 0, 'files': []}

    @staticmethod
    def sanitize_filename(filename: str) -> str:
        """
        ğŸ§¹ æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦
        
        å‚æ•°:
            filename: åŸå§‹æ–‡ä»¶å
            
        è¿”å›:
            æ¸…ç†åçš„æ–‡ä»¶å
        """
        # ğŸ¯ åªä¿ç•™æ–‡ä»¶åéƒ¨åˆ†
        filename = Path(filename).name
        
        # ğŸ§¹ ç§»é™¤éæ³•å­—ç¬¦
        filename = re.sub(r'[<>:\"/\\|?*]', '_', filename)
        filename = re.sub(r'[^\w\-_\.]', '_', filename)
        
        # ğŸ“ é™åˆ¶é•¿åº¦
        if len(filename) > 200:
            name, ext = os.path.splitext(filename)
            filename = name[:200-len(ext)] + ext
        
        return filename
        
    def cleanup(self):
        """ğŸ§¹ æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†æ–‡ä»¶å¤„ç†å™¨èµ„æº")
        self.executor.shutdown(wait=True)
        logger.info("âœ… æ–‡ä»¶å¤„ç†å™¨èµ„æºå·²æ¸…ç†")


# ğŸŒ åˆ›å»ºå…¨å±€å®ä¾‹
file_processor = FileProcessor()